{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# noinspection PyUnresolvedReferences\n",
    "# noinspection PyUnresolvedReferences\n",
    "# from ipynb.fs.full.preparation import expanded_df, expanded_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# noinspection PyUnresolvedReferences\n",
    "from ipynb.fs.full.full_data_3 import full_scale_df_3\n",
    "from ipynb.fs.full.full_data_5 import full_scale_df_5\n",
    "from ipynb.fs.full.full_data_7 import full_scale_df_7\n",
    "from ipynb.fs.full.full_data_9 import full_scale_df_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from decmon.learning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We drop columns that are not numeric (and in our case, present in the dataset in other forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['formula', 'strategy', 'trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TARGET = 'strategy_id'\n",
    "N_CLASSES = 3 # orchestration, migration, choreography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(full_scale_df.groupby(['formula']).max())\n",
    "# indexed = full_scale_df.set_index(['formula'], append=True).swaplevel(0, 1).sort_values(['formula', 'nb_progressions'], ascending=True)\n",
    "# indexed.head()\n",
    "# indexed['strategy_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = indexed.query('nb_progressions == nb_progressions.max()')\n",
    "# test\n",
    "# idx = indexed.groupby(level=0)['nb_progressions'].mean()\n",
    "# indexed[indexed.index.isin(idx)]\n",
    "# full_scale_df2 = full_scale_df.sort_values(['nb_progressions'], ascending=True).groupby(['formula']).agg(f)\n",
    "# full_scale_df2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final_df = clean_df(full_scale_df2, cols_to_drop)\n",
    "# final_df['strategy_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = prepare_learning_sets(final_df, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mgzip\n",
    "import pickle\n",
    "\n",
    "# filename = 'finalized_classifier.mgzip.sav'\n",
    "filename = 'finalized_classifier.sav'\n",
    "def store_model(name: str, model: any, zip=False):\n",
    "    if zip:\n",
    "        with mgzip.open(name, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "    else:\n",
    "        with open(name,'wb') as f:\n",
    "            pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def chrono(label: str, start: float=time.time()):\n",
    "    current = time.time()\n",
    "    print(f\"--- {label}: %s seconds ---\" % (current - start))\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify_by_metric(original_df: DataFrame, metric: str, technique: any):\n",
    "    f = dict.fromkeys(original_df, 'first')\n",
    "    f.update({\n",
    "        'x':'mean',\n",
    "        'trace_len':'mean', \n",
    "        'num_mess':'mean', \n",
    "        'size_mess':'mean', \n",
    "        'nb_progressions':'mean',\n",
    "        })\n",
    "    \n",
    "    print(f\"Metric: {metric}\")\n",
    "    newdf = original_df.sort_values([metric], ascending=True).groupby(['formula']).agg(f)\n",
    "    newdf.reset_index(inplace=True, drop=True)\n",
    "    fdf = clean_df(newdf, cols_to_drop)\n",
    "    print(f\"Value counts:\\n{fdf['strategy_id'].value_counts()}\")\n",
    "    X_train, X_test, y_train, y_test = prepare_learning_sets(fdf, TARGET)\n",
    "    print(f\"Training Dataset size: {X_train.size}\")\n",
    "    print(f\"Testing Dataset size: {X_test.size}\")\n",
    "    timer = chrono(\"Training start\")\n",
    "    classifier = technique.fit(X_train, y_train)\n",
    "    chrono(\"Training end\", timer)\n",
    "    mean_accuracy = classifier.score(X_test, y_test)\n",
    "    print(f\"Accuracy: {mean_accuracy}\")\n",
    "    timer = chrono(\"Testing start\")\n",
    "    pred_y = classifier.predict(X_test)\n",
    "    chrono(\"Testing end\", timer)\n",
    "    f1 = f1_score(pred_y, y_test, labels=[0, 1, 2], average=None)\n",
    "    print(f\"F1: {f1}\")\n",
    "    print(f\"------------------------\")\n",
    "    return classifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System dim. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: nb_progressions\n",
      "Value counts:\n",
      "2    14102\n",
      "0      557\n",
      "1       12\n",
      "Name: strategy_id, dtype: int64\n",
      "Training Dataset size: 3809799\n",
      "Testing Dataset size: 1633142\n",
      "--- Training start: 395.0288941860199 seconds ---\n",
      "--- Training end: 0.005733013153076172 seconds ---\n",
      "Accuracy: 0.953430258973194\n",
      "--- Testing start: 395.36573934555054 seconds ---\n",
      "--- Testing end: 0.3583195209503174 seconds ---\n",
      "F1: [0.08108108 0.         0.97611001]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "c = classify_by_metric(full_scale_df_3, 'nb_progressions', KNeighborsClassifier(n_neighbors=N_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_model(\"finalized_classifier.sav\", c) # 30MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: nb_progressions\n",
      "Value counts:\n",
      "2    14102\n",
      "0      557\n",
      "1       12\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.953430258973194\n",
      "F1: [0.08108108 0.         0.97611001]\n",
      "------------------------\n",
      "Metric: num_mess\n",
      "Value counts:\n",
      "1    12228\n",
      "0     2417\n",
      "2       26\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.8671058609722854\n",
      "F1: [0.53344077 0.92258833 0.        ]\n",
      "------------------------\n",
      "Metric: size_mess\n",
      "Value counts:\n",
      "2    13246\n",
      "0     1273\n",
      "1      152\n",
      "Name: strategy_id, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m classify_by_metric(full_scale_df_3, \u001b[39m'\u001b[39m\u001b[39mnb_progressions\u001b[39m\u001b[39m'\u001b[39m, KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39mN_CLASSES))\n\u001b[1;32m      2\u001b[0m classify_by_metric(full_scale_df_3, \u001b[39m'\u001b[39m\u001b[39mnum_mess\u001b[39m\u001b[39m'\u001b[39m, KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39mN_CLASSES))\n\u001b[0;32m----> 3\u001b[0m classify_by_metric(full_scale_df_3, \u001b[39m'\u001b[39;49m\u001b[39msize_mess\u001b[39;49m\u001b[39m'\u001b[39;49m, KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39;49mN_CLASSES))\n\u001b[1;32m      4\u001b[0m classify_by_metric(full_scale_df_3, \u001b[39m'\u001b[39m\u001b[39mtrace_len\u001b[39m\u001b[39m'\u001b[39m, KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39mN_CLASSES))\n",
      "Cell \u001b[0;32mIn[37], line 20\u001b[0m, in \u001b[0;36mclassify_by_metric\u001b[0;34m(original_df, metric, technique)\u001b[0m\n\u001b[1;32m     18\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m prepare_learning_sets(fdf, TARGET)\n\u001b[1;32m     19\u001b[0m classifier \u001b[39m=\u001b[39m technique\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 20\u001b[0m mean_accuracy \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mscore(X_test, y_test)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m{\u001b[39;00mmean_accuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m pred_y \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/base.py:649\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 649\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[1;32m    220\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    232\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    235\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/neighbors/_base.py:824\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    817\u001b[0m use_pairwise_distances_reductions \u001b[39m=\u001b[39m (\n\u001b[1;32m    818\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    819\u001b[0m     \u001b[39mand\u001b[39;00m ArgKmin\u001b[39m.\u001b[39mis_usable_for(\n\u001b[1;32m    820\u001b[0m         X \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_\n\u001b[1;32m    821\u001b[0m     )\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    823\u001b[0m \u001b[39mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 824\u001b[0m     results \u001b[39m=\u001b[39m ArgKmin\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    825\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    826\u001b[0m         Y\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[1;32m    827\u001b[0m         k\u001b[39m=\u001b[39;49mn_neighbors,\n\u001b[1;32m    828\u001b[0m         metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[1;32m    829\u001b[0m         metric_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_params_,\n\u001b[1;32m    830\u001b[0m         strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    831\u001b[0m         return_distance\u001b[39m=\u001b[39;49mreturn_distance,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    834\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    835\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m issparse(X)\n\u001b[1;32m    836\u001b[0m ):\n\u001b[1;32m    837\u001b[0m     results \u001b[39m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    838\u001b[0m         X, n_neighbors\u001b[39m=\u001b[39mn_neighbors, return_distance\u001b[39m=\u001b[39mreturn_distance\n\u001b[1;32m    839\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:277\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mreturns.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mreturn\u001b[39;00m ArgKmin64\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    278\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    279\u001b[0m         Y\u001b[39m=\u001b[39;49mY,\n\u001b[1;32m    280\u001b[0m         k\u001b[39m=\u001b[39;49mk,\n\u001b[1;32m    281\u001b[0m         metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    282\u001b[0m         chunk_size\u001b[39m=\u001b[39;49mchunk_size,\n\u001b[1;32m    283\u001b[0m         metric_kwargs\u001b[39m=\u001b[39;49mmetric_kwargs,\n\u001b[1;32m    284\u001b[0m         strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    285\u001b[0m         return_distance\u001b[39m=\u001b[39;49mreturn_distance,\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat32:\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m ArgKmin32\u001b[39m.\u001b[39mcompute(\n\u001b[1;32m    290\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    291\u001b[0m         Y\u001b[39m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m         return_distance\u001b[39m=\u001b[39mreturn_distance,\n\u001b[1;32m    298\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:95\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/threadpoolctl.py:171\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m, value, traceback):\n\u001b[1;32m    172\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    174\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39mcls\u001b[39m, controller, \u001b[39m*\u001b[39m, limits\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_api\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classify_by_metric(full_scale_df_3, 'nb_progressions', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_3, 'num_mess', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_3, 'size_mess', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_3, 'trace_len', KNeighborsClassifier(n_neighbors=N_CLASSES))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System dim. 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: nb_progressions\n",
      "Value counts:\n",
      "2    18621\n",
      "0      403\n",
      "1        2\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.9774001401541695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enniovisco/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.11034483 0.         0.9885547 ]\n",
      "------------------------\n",
      "Metric: num_mess\n",
      "Value counts:\n",
      "1    15501\n",
      "0     3525\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.8826208829712684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enniovisco/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.64132762 0.92982824 0.        ]\n",
      "------------------------\n",
      "Metric: size_mess\n",
      "Value counts:\n",
      "2    17346\n",
      "0     1429\n",
      "1      251\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.956552207428171\n",
      "F1: [0.75481386 0.54135338 0.97677075]\n",
      "------------------------\n",
      "Metric: trace_len\n",
      "Value counts:\n",
      "2    17283\n",
      "0     1741\n",
      "1        2\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.8950595655220743\n",
      "F1: [0.13062409 0.         0.9441596 ]\n",
      "------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enniovisco/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "classify_by_metric(full_scale_df_5, 'nb_progressions', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_5, 'num_mess', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_5, 'size_mess', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_5, 'trace_len', KNeighborsClassifier(n_neighbors=N_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: nb_progressions\n",
      "Value counts:\n",
      "2    23683\n",
      "0      404\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.9835339698353397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enniovisco/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.25157233 0.         0.99167541]\n",
      "------------------------\n",
      "Metric: num_mess\n",
      "Value counts:\n",
      "1    19290\n",
      "0     4797\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.8872284488722845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enniovisco/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.68026677 0.93154137 0.        ]\n",
      "------------------------\n",
      "Metric: size_mess\n",
      "Value counts:\n",
      "2    21980\n",
      "0     1681\n",
      "1      426\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.9564134495641345\n",
      "F1: [0.77127072 0.53386454 0.97698902]\n",
      "------------------------\n",
      "Metric: trace_len\n",
      "Value counts:\n",
      "2    22188\n",
      "0     1895\n",
      "1        4\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.9104746091047461\n",
      "F1: [0.15223097 0.         0.95274268]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "classify_by_metric(full_scale_df_7, 'nb_progressions', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_7, 'num_mess', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_7, 'size_mess', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_7, 'trace_len', KNeighborsClassifier(n_neighbors=N_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: nb_progressions\n",
      "Value counts:\n",
      "2    24710\n",
      "0      441\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.9795918367346939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enniovisco/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.15384615 0.         0.98967136]\n",
      "------------------------\n",
      "Metric: num_mess\n",
      "Value counts:\n",
      "1    18820\n",
      "0     6331\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.884574609064405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enniovisco/.pyenv/versions/3.10.6/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: [0.74702295 0.92522963 0.        ]\n",
      "------------------------\n",
      "Metric: size_mess\n",
      "Value counts:\n",
      "2    22725\n",
      "0     1825\n",
      "1      601\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.956268221574344\n",
      "F1: [0.78172589 0.62908012 0.97676107]\n",
      "------------------------\n",
      "Metric: trace_len\n",
      "Value counts:\n",
      "2    23109\n",
      "0     2039\n",
      "1        3\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.9147892923403127\n",
      "F1: [0.21542228 0.         0.95494991]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "classify_by_metric(full_scale_df_9, 'nb_progressions', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_9, 'num_mess', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_9, 'size_mess', KNeighborsClassifier(n_neighbors=N_CLASSES))\n",
    "classify_by_metric(full_scale_df_9, 'trace_len', KNeighborsClassifier(n_neighbors=N_CLASSES))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dim 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: nb_progressions\n",
      "Value counts:\n",
      "2    14102\n",
      "0      557\n",
      "1       12\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.9606996819627442\n",
      "F1: [0.         0.         0.97995597]\n",
      "------------------------\n",
      "Metric: num_mess\n",
      "Value counts:\n",
      "1    12228\n",
      "0     2417\n",
      "2       26\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.8246251703771014\n",
      "F1: [0.         0.90388446 0.        ]\n",
      "------------------------\n",
      "Metric: size_mess\n",
      "Value counts:\n",
      "2    13246\n",
      "0     1273\n",
      "1      152\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.8975465697410268\n",
      "F1: [0.         0.         0.94600742]\n",
      "------------------------\n",
      "Metric: trace_len\n",
      "Value counts:\n",
      "2    12969\n",
      "0     1696\n",
      "1        6\n",
      "Name: strategy_id, dtype: int64\n",
      "Accuracy: 0.8832348932303499\n",
      "F1: [0.         0.93799759]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "classify_by_metric(full_scale_df_3, 'nb_progressions', svm.SVC(decision_function_shape='ovr'))\n",
    "classify_by_metric(full_scale_df_3, 'num_mess', svm.SVC(decision_function_shape='ovr'))\n",
    "classify_by_metric(full_scale_df_3, 'size_mess', svm.SVC(decision_function_shape='ovr'))\n",
    "classify_by_metric(full_scale_df_3, 'trace_len', svm.SVC(decision_function_shape='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "97f6cf32027ae336cfa3b32f93b8f218de523101cad422742134bfca693b217a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
